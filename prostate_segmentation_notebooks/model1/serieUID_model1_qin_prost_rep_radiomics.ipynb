{"cells":[{"cell_type":"markdown","metadata":{"id":"WnbkuvxW0Ntp"},"source":["# Prostate segmentation evaluation on IDC collection -- Radiomics -- QIN prostate repeatability\n","*   Dataset : [QIN-Prostate-Repeatability]()\n","*   Goal : Prostate segmentation using Task24 Prostate nnU-net pre-trained model, T2 input"]},{"cell_type":"markdown","source":["# Custom functions"],"metadata":{"id":"TZALQu_dnyFq"}},{"cell_type":"markdown","source":["## IDC processing"],"metadata":{"id":"QXh4ITBM7d6W"}},{"cell_type":"code","source":["def parse_json_dcmqi(json_path):\n","  \"\"\"\n","  Get dictionary of CodeMeaning : labelID\n","  json_path : str, dcmqi json path\n","  \"\"\"\n","  out_dic = {}\n","  data = json.load(open(json_path))\n","  for segment_dic_arr in data[\"segmentAttributes\"]:\n","    dic_in = segment_dic_arr[0]\n","    out_dic[dic_in[\"SegmentedPropertyTypeCodeSequence\"][\"CodeMeaning\"]] \\\n","    = dic_in[\"labelID\"]\n","  return out_dic"],"metadata":{"id":"t3n_sUaUmMHc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_image_dcm_to_nrrd(input_path, output_path_root, target_format=\"nrrd\", prefix=\"\"):\n","  \"\"\"\n","  Conversion of DICOM MR data to NIFTI using dcm2niix\n","  input_path : str, folder containing DICOM instances .dcm\n","  output_path_root : str, output folder\n","  prefix : str, prefix for output file name\n","  \"\"\"\n","  if not os.path.exists(output_path_root):\n","    !mkdir -p $output_path_root\n","  !dcm2niix -z y -m y -f %i_{prefix} -o $output_path_root $input_path"],"metadata":{"id":"ADnWwCO22Dpt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_seg_to_nii(input_path, output_path):\n","  \"\"\"\n","  Conversion of SEG DICOM object to NIFTI\n","  input_path : str, input_path DICOM folder\n","  output_path : str, folder output paths\n","  \"\"\"\n","  if not os.path.exists(output_path):\n","    !mkdir -p $output_path\n","  print(f'input path : {input_path}')\n","  print(f'output_path : {output_path}')\n","  !segimage2itkimage --inputDICOM $input_path --outputDirectory $output_path \\\n","  --outputType nii"],"metadata":{"id":"Pabz_xHTFzxs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_dcm_sorted(input_path,output_path, idc_df):\n","  \"\"\"\n","  Convert DCM MR sorted by PatID/StudyUID/SerieUID in NIFTI format\n","  input_path : str, root folder containing all series sorted by patid/studyUID/serieUID/sopUID.dcm\n","  output_path : str, root folder of where to store converted MR T2 series\n","  idc_df : pandas.Dataframe, contains IDC metadata to retrieve modality information etc per serieUID\n","  \"\"\"\n","  for serie_folder in sorted(glob.glob(os.path.join(input_path, \"**\", \"**\", \"*\"))):#, recursive = True):\n","    path_serie_dcm_lst = glob.glob(os.path.join(serie_folder, \"*.dcm\"))\n","    modality = idc_df[idc_df[\"SeriesInstanceUID\"] == path_serie_dcm_lst[0].split('/')[-2]][\"Modality\"].iloc[0]#'SEG' if pydicom.dcmread(path_serie_dcm_lst[0]).Modality == \"SEG\" else \"MR\"\n","    seriesInstanceUID = serie_folder.split(\"/\")[-1]\n","    studyInstanceUID = serie_folder.split(\"/\")[-2]\n","    patientID = serie_folder.split(\"/\")[-3]\n","    print(f\"Serie processed : {serie_folder}\")\n","    print(f\"SeriesDescription : {pydicom.read_file(glob.glob(os.path.join(serie_folder, '*.dcm'))[0]).SeriesDescription}\")\n","    print(f\"Modality : {pydicom.read_file(glob.glob(os.path.join(serie_folder, '*.dcm'))[0]).Modality}\")\n","    #convert to nii\n","    convert_image_dcm_to_nrrd(input_path=serie_folder,\n","                           output_path_root=output_path,\n","                           prefix=f\"{seriesInstanceUID}\")"],"metadata":{"id":"HO2dWXPBF3Sf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def download_idc_data_serie_uid(idc_df, out_path, out_path_nii):\n","  \"\"\"\n","  Download IDC data from gcs_urls retrieved from BigQuery\n","  idc_df : pandas.Dataframe, contains MR series DICOM metadata and gcs_urls\n","  out_path_nii : str, output path folder for converted NIFTI volumes MR T2\n","  \"\"\"\n","  # save the list of GCS URLs into a file\n","  selection_manifest = os.path.join(os.environ[\"IDC_IMG_Downloads\"], \"idc_manifest.txt\")\n","  idc_df[\"gcs_url\"].to_csv(selection_manifest, header=False, index=False)\n","  !cat {selection_manifest} | gsutil -m cp -I {os.environ[\"IDC_IMG_Downloads\"]}\n","  !python dicomsort/dicomsort.py -k -u {os.environ[\"IDC_IMG_Downloads\"]} {os.environ[\"IDC_IMG_Downloads_Sorted\"]}/%PatientID/%StudyInstanceUID/%SeriesInstanceUID/%SOPInstanceUID.dcm\n","  # !rm -rf {os.environ[\"qin_prostate_rep_dicom\"]+\"/*\"}\n","  in_mv = os.environ['IDC_IMG_Downloads_Sorted']+'/*'\n","  !mv $in_mv $out_path\n","  convert_dcm_sorted(input_path=out_path,\n","                  output_path=out_path_nii, idc_df=idc_df)"],"metadata":{"id":"9zBhg_TO0P_D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Radiomics imports and config"],"metadata":{"id":"LiFJwNTudqZ4"}},{"cell_type":"markdown","source":["This function below might have to be updated depending on the format of your dicomseg json file."],"metadata":{"id":"ilCLRg3enCdM"}},{"cell_type":"markdown","source":["If you have a single nii file from nnUNet that holds multiple label values, this splits it into multiple segments."],"metadata":{"id":"fenj7DGonLg6"}},{"cell_type":"markdown","source":["This is the function to compute the features"],"metadata":{"id":"wzhNdeKvnTWi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q3e2zVFwlxbI"},"outputs":[],"source":["def compute_pyradiomics_3D_features(ct_nifti_path,\n","                                    label_values,\n","                                    label_names,\n","                                    split_pred_nifti_path,\n","                                    nnunet_shape_features_code_mapping_df):\n","\n","  \"\"\"Function to compute pyradiomics 3D features for each label in a nifti file.\n","\n","\n","  Inputs:\n","    ct_nifti_path            : the MR nifti file\n","    label_values             : the label value for each of the segments from the json file\n","    label_names              : the corresponding label name for each of the segments\n","    split_pred_nifti_path    : where to save the individual nii segments needed\n","                               for pyradiomics\n","    nnunet_shape_features_code_mapping_df : the df where we will obtain the\n","                                            list of the shape features to\n","                                            compute\n","\n","  Outputs:\n","    Writes the features_csv_path_nnunet to disk.\n","\n","  \"\"\"\n","\n","  # Get the names of the features from the nnunet_shape_features_code_mapping_df\n","  # shape_features = list(nnunet_shape_features_code_mapping_df['shape_feature'].values)\n","\n","  # Instantiate the extractor and modify the settings to keep the 3D shape features\n","  extractor = featureextractor.RadiomicsFeatureExtractor()\n","  extractor.settings['minimumROIDimensions'] = 3\n","  extractor.settings['correctMask'] = True\n","  # extractor.settings['geometryTolerance'] = 1e-2\n","  # extractor.disableAllFeatures()\n","  extractor.enableAllFeatures()\n","  # extractor.enableFeaturesByName(shape=shape_features)\n","\n","  # Calculate features for each label and create a dataframe\n","  num_labels = len([f for f in os.listdir(split_pred_nifti_path) if f.endswith('.nii.gz')])\n","  df_list = []\n","  for n in range(0,num_labels):\n","    mask_path = os.path.join(split_pred_nifti_path, str(label_values[n]) + '.nii.gz')\n","    print(mask_path)\n","    corresponding_label_value = label_values[n]#label_values[label_names.index(label_names[n])]\n","    # Run the extractor\n","    print(mask_path)\n","    assert os.path.exists(mask_path)\n","    assert os.path.exists(ct_nifti_path)\n","    result = extractor.execute(ct_nifti_path, mask_path, label=corresponding_label_value) # dictionary\n","    # keep only the features we want\n","    # Get the corresponding label number -- all might not be present\n","    dict_keep = {'ReferencedSegment': corresponding_label_value,\n","                 'label_name': label_names[n]}\n","    keys_keep = [f for f in result.keys()]# if 'original_shape' in f]\n","    # Just keep the feature keys we want\n","    dict_keep_new_values = {key_keep: result[key_keep] for key_keep in keys_keep}\n","    dict_keep.update(dict_keep_new_values)\n","    df1 = pd.DataFrame([dict_keep])\n","    # change values of columns to remove original_shape_\n","    df1.columns = df1.columns.str.replace('original_shape_', '')\n","    # Append to the ReferencedSegment and label_name df\n","    df_list.append(df1)\n","\n","  # concat all label features\n","  df = pd.concat(df_list)\n","\n","  return df"]},{"cell_type":"markdown","source":["Get the label values and label names from the dicomseg json file. If you have multiple labels in one nifti file, call `split_nii` to split into separate files. The compute the radiomics features for each of the labels. `ct_nifti_path` is the MR nifti file."],"metadata":{"id":"dBWh6k4fmVZq"}},{"cell_type":"markdown","metadata":{"id":"a8GPDXZW00j5"},"source":["# Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XSg6W2HXzsoG"},"outputs":[],"source":["#colab\n","from google.colab import auth\n","auth.authenticate_user()"]},{"cell_type":"markdown","metadata":{"id":"y1ZYYVPHz_xm"},"source":["# Setup GCP Project ID"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g1EN9Dnz0CU4"},"outputs":[],"source":["import os\n","project_id = \"idc-sandbox-003\"\n","os.environ[\"GCP_PROJECT_ID\"] = project_id"]},{"cell_type":"markdown","metadata":{"id":"eRtmCas7dT6D"},"source":["# Setup of the Colab VM\n","\n","\n","\n","In the following cells we will confirm you have a GPU before doing anything else, and will install and import all the Python dependencies.\n","\n","The main python packages we need to install are:\n","* `nnunet` - which is the [codebase for the nn-UNet framework](https://github.com/MIC-DKFZ/nnUNet) we are going to be using for the segmentation step;\n","* `pydicom`, a Python [package](https://github.com/pydicom/pydicom) that lets the use read, modify, and write DICOM data in an easy \"pythonic\" way - that we are going to use to distinguish different DICOM objects from each other."]},{"cell_type":"markdown","metadata":{"id":"zLvysANUArnm"},"source":["## GPU checks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pf2j172mddvK"},"outputs":[],"source":["# check wether the Colab Instance was correctly initialized with a GPU instance\n","gpu_list = !nvidia-smi --list-gpus\n","\n","has_gpu = False if \"failed\" in gpu_list[0] else True\n","\n","if not has_gpu:\n","  print(\"Your Colab VM does not have a GPU - check \\\"Runtime > Change runtime type\\\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kL6xCvo3eKQ0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684142604779,"user_tz":240,"elapsed":7,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"83b3d0a1-60a0-4111-d412-22a089beddf0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon May 15 09:23:24 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# check which model of GPU the notebook is equipped with - a Tesla K80 or T4\n","# T4 is the best performing on the two - and can about half the GPU processing time\n","\n","!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"ZJhwBz2ABT_p"},"source":["## Environment Setup\n","\n","Here we will configure the Linux environment variables needed to run the nnU-Net pipeline.\n","\n","Three main variables are needed by default to run the nnU-Net segmentation pipelines:\n","* `nnUNet_raw_data_base` is the path to the folder where the segmentation pipeline expects to find the data to process;\n","* `nnUNet_preprocessed` is the path to the folder where the preprocessed data are saved;\n","* `RESULTS_FOLDER` is the path to the folder storing by default the model weights and, in our case, for simplicity, the segmentation masks produced by the pipeline.\n","\n","We will use the additional variable `PATH_TO_MODEL_FILE` to point to the location where the pre-trained model weights for the chosen model will be stored (more on this later).\n","\n","Please notice that these variables need to be set using `os.environ[]` in Google Colab - as `!export` is not sufficient to guarantee the variables are kept from one cell to the other. For more in-depth information regarding what the nnU-Net framework uses these folders for, please visit [the dedicated nnU-Net documentation page](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/setting_up_paths.md)"]},{"cell_type":"markdown","metadata":{"id":"40E3HnI5A0SX"},"source":["## Install command-line tools\n","\n","\n","[Plastimatch](https://plastimatch.org/index.html) is considered to be the swiss army knife of medical images processing: we will use it to convert DICOM (CT, RTSTRUCT) series to NRRD files - but it can be used for a multitude of other tasks, such as registration, resampling, cropping, and computing statistics to name a few. Plastimatch is also available as a 3DSlicer plug-in and can be used directly from the Slicer GUI.\n","\n","For the sake of clarity and simplicity, we will call Plastimatch from a very simple [Python wrapper](https://github.com/denbonte/pyplastimatch) written for the occasion (unfortunately, Plastimatch does not provide an official one)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZZL6-ByHA7XY"},"outputs":[],"source":["%%capture\n","!sudo apt update\n","\n","!sudo apt install plastimatch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LMovHnKgBEfC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684142609653,"user_tz":240,"elapsed":5,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"6f8ed61e-d268-4210-b86b-54267378f31a"},"outputs":[{"output_type":"stream","name":"stdout","text":["plastimatch version 1.8.0\n"]}],"source":["!echo $(plastimatch --version)"]},{"cell_type":"markdown","metadata":{"id":"K_8zlhmdo0HD"},"source":["[dcmqi](https://github.com/QIICR/dcmqi) is an open source library that can help with the conversion between imaging research formats and the standard DICOM representation for image analysis results. More specifically, you can use dcmqi convert DICOM Segmentation objects (DICOM SEG) into research formats, such as NIfTI and NRRD."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KAkmz4jApGh8"},"outputs":[],"source":["%%capture\n","!wget https://github.com/QIICR/dcmqi/releases/download/v1.2.5/dcmqi-1.2.5-linux.tar.gz\n","!tar zxvf dcmqi-1.2.5-linux.tar.gz\n","!cp dcmqi-1.2.5-linux/bin/* /usr/local/bin/"]},{"cell_type":"markdown","metadata":{"id":"fFRWendbBH72"},"source":["Finally, we are going to install [Subversion](https://subversion.apache.org/), a tool that will allow us to clone GitHub repositories only partially (to save time and space)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YBEJRe-2BKah"},"outputs":[],"source":["%%capture\n","\n","!sudo apt install subversion"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WI1_BixWBN1O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684142612999,"user_tz":240,"elapsed":3,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"3df9afb0-b1fe-450f-c798-508b9a4b818b"},"outputs":[{"output_type":"stream","name":"stdout","text":["svn, version 1.13.0 (r1867053) compiled May 12 2022, 20:47:08 on x86_64-pc-linux-gnu\n"]}],"source":["!echo $(svn --version | head -n 2)"]},{"cell_type":"markdown","metadata":{"id":"0Ev-JlpCAuMs"},"source":["## Install Python packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7XMzq-8nRvKd"},"outputs":[],"source":["%%capture\n","!pip install nnunet\n","!pip install pydicom\n","!pip install nibabel\n","!pip install dcm2niix\n","!pip install SimpleITK\n","!pip install medpy\n","!pip install pyradiomics"]},{"cell_type":"markdown","metadata":{"id":"62yhEkkjITzn"},"source":["Unpack and install model we downloaded earlier (under `PATH_TO_MODEL_FILE`). This step can take about 1-2 minutes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QOVsPuzxIOXX"},"outputs":[],"source":["%%capture\n","!nnUNet_install_pretrained_model_from_zip $PATH_TO_MODEL_FILE"]},{"cell_type":"markdown","metadata":{"id":"BP1tahM9tzlm"},"source":["Next we set up few things to help with visualization of the segmentations later."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cURjj8rzAa2L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684142637877,"user_tz":240,"elapsed":5,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"6a374897-f32d-4e09-a165-cf8e49e1de45"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","This Colab instance is equipped with a GPU.\n"]}],"source":["import os\n","import sys\n","import shutil\n","import csv\n","import random\n","\n","import os\n","import glob\n","import csv\n","import json\n","\n","import nibabel as nib\n","\n","import time\n","import gdown\n","\n","import json\n","import pprint\n","import numpy as np\n","import pandas as pd\n","\n","import pydicom\n","import nibabel as nib\n","import SimpleITK as sitk\n","from medpy.metric.binary import asd\n","\n","\n","from radiomics import featureextractor\n","# from medpy.metric.binary import dc as dice_coef\n","# from medpy.metric.binary import hd as hausdorff_distance\n","# from medpy.metric.binary import asd as avg_surf_distance\n","\n","# from medpy.filter.binary import largest_connected_component\n","\n","# use the \"tensorflow_version\" magic to make sure TF 1.x is imported\n","# %tensorflow_version 2.x\n","# import tensorflow as tf\n","# import keras\n","\n","print(\"\\nThis Colab instance is equipped with a GPU.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UrAh2kjqb2Be","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684142640821,"user_tz":240,"elapsed":2946,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"776d3198-7839-42fd-8504-a5d310dcca9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Checked out revision 25.\n"]}],"source":["# PyPlastimatch - python wrapper for Plastimatch (and interactive notebook visualisation)\n","!svn checkout https://github.com/AIM-Harvard/pyplastimatch/trunk/pyplastimatch pyplastimatch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GsePTNBmM9sw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684142640822,"user_tz":240,"elapsed":9,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"58382b51-ed1d-42fe-f2a4-52433d97fa1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'dicomsort' already exists and is not an empty directory.\n"]}],"source":["# dicomsort is the pythong package that can sort DICOM files into\n","# folder organization based on user-specified DICOM attributes\n","!git clone https://github.com/pieper/dicomsort.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0s9aRassGOQ_"},"outputs":[],"source":["from pyplastimatch import pyplastimatch as pypla\n","from pyplastimatch.utils import viz as viz_utils\n","from pyplastimatch.utils import data as data_utils"]},{"cell_type":"markdown","metadata":{"id":"Duil1tviGWaG"},"source":["# Data selection, downloading and structuring -- Conversion to DICOM\n","\n","We want to select here the collection named qin-prostate repeatibility, and more particularly the two timepoints per patient ID for further analysis."]},{"cell_type":"markdown","metadata":{"id":"naJ5OAKZnZpG"},"source":["In order to use data hosted by IDC effectively, you will need to utilize metadata to navigate what data is available and to select specific files that are relevant in your analysis. The main metadata table you will need for this purpose is the [`bigquery-public-data.idc_current.dicom_all`](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=idc_current&t=dicom_all&page=table) table.\n","\n","This query has one row per file hosted by IDC. All of IDC data is in DICOM format, and each of the rows in this table will have all of the DICOM attributes extracted from a given file. It will also have various columns containing non-DICOM metadata, such as the name of the collection where the file is included, size of the file, and URL that can be used to retrieve that file.\n","\n","To query IDC BigQuery tables, you can use one of the following approaches:\n","1. `%%bigquery` magic will allow you to define your query in plain SQL, and load the result of the query into a Pandas dataframe.\n","2. [BigQuery Python API](https://googleapis.dev/python/bigquery/latest/index.html) is more flexible in allowing you to parameterize your query.\n","3. [Google Cloud BigQuery console](https://console.cloud.google.com/bigquery) is very convenient for interactive query exploration of tables.\n","4. [`gcloud bq`](https://cloud.google.com/bigquery/docs/bq-command-line-tool) is the command line tool that comes as part of [Cloud SDK](https://cloud.google.com/sdk) and is convenient for scripting interactions from the shell. Cloud SDK is preinstalled on Colab.\n","\n","In the following cells we will utilize `%%bigquery`, Python BigQuery SDK and BigQuery console for working with IDC BigQuery tables.\n","\n","First, to verify that you are authenticated, and your project ID is working, let's run a test query against IDC BigQuery table to get the summary statistics about the  of data available in IDC.\n"]},{"cell_type":"markdown","metadata":{"id":"t9YKMGVvVZX_"},"source":["Given `SeriesInstanceUID` value identifying the image series, we can query the IDC metadata table to get the list of files (defined by the Google Storage URLs) corresponding to this series.\n","\n","All of the DICOM metadata for each of the DICOM files is available in the BigQuery table we will be querying. We will get not just the `gcs_url`, but also identifiers for the Study, Series and Instance, to better understand organization of data, and since `StudyInstanceUID` will be handy later when we get to the visualization of the data."]},{"cell_type":"code","source":["from google.cloud import bigquery\n","bq_client = bigquery.Client(os.environ[\"GCP_PROJECT_ID\"])"],"metadata":{"id":"uLzAa7kH4mBZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Get SerieUIDs in bucket processed from nnunet"],"metadata":{"id":"QjirvyGv_poC"}},{"cell_type":"code","source":["!rm bucketUIDs_nnunet.csv\n","!gcloud storage ls --recursive gs://idc_qin_prostate_repeatability/model1/preds_processed_dcm/* > bucketUIDs_nnunet.csv\n","serieUID_nnunet_processed = pd.read_csv(\"bucketUIDs_nnunet.csv\", names=[\"serieUID\"], skiprows=[0])\n","seriesInstanceUID_nnunet_processed_lst = [x.split(\"/\")[-1].split(\"_\")[1].replace(\".dcm\",\"\") for x in serieUID_nnunet_processed.serieUID.values]"],"metadata":{"id":"-rSpFb0qAICu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(seriesInstanceUID_nnunet_processed_lst)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ClvXN2pIPfag","executionInfo":{"status":"ok","timestamp":1684142648785,"user_tz":240,"elapsed":9,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"27bdbee0-07b0-401c-826a-ee283303b942"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30"]},"metadata":{},"execution_count":87}]},{"cell_type":"markdown","source":["Get processed series -- extracted radiomics for custom bigquery table"],"metadata":{"id":"YOAsoXVmPRmy"}},{"cell_type":"code","source":["from google.cloud import bigquery\n","selection_query = f\"\"\"\n","    SELECT\n","      DISTINCT(RefSerieUID)\n","    FROM\n","      `idc-sandbox-003.qin_prostate_repeatability_serieUID.model1_preds_prostate_radiomics` as eval_table\"\"\"\n","selection_result = bq_client.query(selection_query)\n","selection_df = selection_result.result().to_dataframe()\n","eval_refSerieUID = selection_df.RefSerieUID.values"],"metadata":{"id":"ZzNvW3i7PRm7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["not_processed_RefSerieUID = set(seriesInstanceUID_nnunet_processed_lst) - set(eval_refSerieUID)"],"metadata":{"id":"gZPHV5dNld9H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(not_processed_RefSerieUID)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDmyTitNlxNE","executionInfo":{"status":"ok","timestamp":1684142653358,"user_tz":240,"elapsed":3,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"84b08b5b-30e5-4bbd-c61e-638565928980"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["29"]},"metadata":{},"execution_count":93}]},{"cell_type":"markdown","source":["# Main loop"],"metadata":{"id":"kNuuz_84JqnK"}},{"cell_type":"markdown","source":["These define the shape features that we are extracting as well as the segments. You will likely have to create your own `nnunet_segments_code_mapping.csv` with the segments of the prostate."],"metadata":{"id":"cEyhvPo2mwfd"}},{"cell_type":"code","source":["seg_rad_segment_nnUNet = \"https://www.dropbox.com/s/4x2lo3ll7srw9jf/radiomics_json_segment.csv?dl=0\"\n","out_path_mod = \"nnunet_segments_code_mapping.csv\"\n","!wget -O $out_path_mod $seg_rad_segment_nnUNet"],"metadata":{"id":"vnJ5lhpPmQhy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684142654908,"user_tz":240,"elapsed":1552,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"fc4d6443-612b-455b-e8a9-7ee5c0a11644"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-05-15 09:24:13--  https://www.dropbox.com/s/4x2lo3ll7srw9jf/radiomics_json_segment.csv?dl=0\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.85.18, 2620:100:6031:18::a27d:5112\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.85.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /s/raw/4x2lo3ll7srw9jf/radiomics_json_segment.csv [following]\n","--2023-05-15 09:24:13--  https://www.dropbox.com/s/raw/4x2lo3ll7srw9jf/radiomics_json_segment.csv\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc5e3ab8a0a65fbcdd5d1eed4afc.dl.dropboxusercontent.com/cd/0/inline/B8EjMWCYhWyN2ojK3rPSuszEQQDzC1_mO8COwxw5l0N2VOUXOmFOhwxOr5QAGuERlrqoOYn2hhGQuBMhmQQvkLkODWS6RtX3iKCxPqun6hcw6LhsUBftJAAUGPMSpMtkUAII5YKwtDNzZPemQvSezGrVtO3NAScSo01EE4ghso05-A/file# [following]\n","--2023-05-15 09:24:14--  https://uc5e3ab8a0a65fbcdd5d1eed4afc.dl.dropboxusercontent.com/cd/0/inline/B8EjMWCYhWyN2ojK3rPSuszEQQDzC1_mO8COwxw5l0N2VOUXOmFOhwxOr5QAGuERlrqoOYn2hhGQuBMhmQQvkLkODWS6RtX3iKCxPqun6hcw6LhsUBftJAAUGPMSpMtkUAII5YKwtDNzZPemQvSezGrVtO3NAScSo01EE4ghso05-A/file\n","Resolving uc5e3ab8a0a65fbcdd5d1eed4afc.dl.dropboxusercontent.com (uc5e3ab8a0a65fbcdd5d1eed4afc.dl.dropboxusercontent.com)... 162.125.80.15, 2620:100:6035:15::a27d:550f\n","Connecting to uc5e3ab8a0a65fbcdd5d1eed4afc.dl.dropboxusercontent.com (uc5e3ab8a0a65fbcdd5d1eed4afc.dl.dropboxusercontent.com)|162.125.80.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 223 [text/plain]\n","Saving to: ‘nnunet_segments_code_mapping.csv’\n","\n","nnunet_segments_cod 100%[===================>]     223  --.-KB/s    in 0s      \n","\n","2023-05-15 09:24:14 (35.7 MB/s) - ‘nnunet_segments_code_mapping.csv’ saved [223/223]\n","\n"]}]},{"cell_type":"code","source":["nnunet_segments_code_mapping_df = pd.read_csv(\"nnunet_segments_code_mapping.csv\")"],"metadata":{"id":"niJam4n-Ob9I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nnunet_segments_code_mapping_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"SHU8Qwi6fuN8","executionInfo":{"status":"ok","timestamp":1684142654909,"user_tz":240,"elapsed":4,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"494502fd-0236-4153-94d6-c13b34ef917f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    segment Finding_CodingSchemeDesignator  Finding_CodeValue  \\\n","0  Prostate                            SCT           41216001   \n","\n","    Finding_CodeMeaning FindingSite_CodingSchemeDesignator  \\\n","0  Anatomical Structure                                SCT   \n","\n","   FindingSite_CodeValue FindingSite_CodeMeaning  \n","0              123037004                Prostate  "],"text/html":["\n","  <div id=\"df-b526e1b5-fd84-4933-bedb-85ebe719f0d0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>segment</th>\n","      <th>Finding_CodingSchemeDesignator</th>\n","      <th>Finding_CodeValue</th>\n","      <th>Finding_CodeMeaning</th>\n","      <th>FindingSite_CodingSchemeDesignator</th>\n","      <th>FindingSite_CodeValue</th>\n","      <th>FindingSite_CodeMeaning</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Prostate</td>\n","      <td>SCT</td>\n","      <td>41216001</td>\n","      <td>Anatomical Structure</td>\n","      <td>SCT</td>\n","      <td>123037004</td>\n","      <td>Prostate</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b526e1b5-fd84-4933-bedb-85ebe719f0d0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b526e1b5-fd84-4933-bedb-85ebe719f0d0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b526e1b5-fd84-4933-bedb-85ebe719f0d0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["from google.cloud import bigquery\n","selection_query = f\"\"\"\n","    SELECT\n","      *\n","    FROM\n","      `bigquery-public-data.idc_v14.dicom_all` as dc_all\n","    WHERE\n","      Modality = 'MR'\n","    AND SeriesInstanceUID IN UNNEST(%s)\"\"\" %list(not_processed_RefSerieUID)\n","selection_result = bq_client.query(selection_query)\n","selection_t2_df = selection_result.result().to_dataframe()"],"metadata":{"id":"zjqgHoMLO_-N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","#nnunet_preds\n","os.environ[\"nnunet_preds\"] = os.path.join(os.getcwd(), \"nnunet_preds\")\n","os.environ[\"nnunet_preds_dcm\"] = os.path.join(os.environ[\"nnunet_preds\"], \"dcm\")\n","os.environ[\"nnunet_preds_nii\"] = os.path.join(os.environ[\"nnunet_preds\"], \"nii\")\n","# #seg files\n","# os.environ[\"idc_seg\"] = os.path.join(os.getcwd(), \"idc_seg\")\n","# os.environ[\"idc_seg_dcm\"] = os.path.join(os.environ[\"idc_seg\"], \"dcm\")\n","# os.environ[\"idc_seg_nii\"] = os.path.join(os.environ[\"idc_seg\"], \"nii\")\n","#idc image files\n","os.environ[\"idc_data\"] = os.path.join(os.getcwd(), \"idc_data\")\n","os.environ[\"idc_data_dcm\"] = os.path.join(os.environ[\"idc_data\"], \"dcm\")\n","os.environ[\"idc_data_nii\"] = os.path.join(os.environ[\"idc_data\"], \"nii\")\n","#idc data\n","os.environ[\"IDC_Downloads\"] = os.path.join(os.getcwd(), \"IDC_Downloads\")\n","os.environ[\"IDC_Downloads_Sorted\"] = os.path.join(os.getcwd(), \"IDC_Downloads_Sorted\")\n","os.environ[\"IDC_IMG_Downloads\"] = os.path.join(os.getcwd(), \"IDC_IMG_Downloads\")\n","os.environ[\"IDC_IMG_Downloads_Sorted\"] = os.path.join(os.getcwd(), \"IDC_IMG_Downloads_Sorted\")\n","#evaluation\n","os.environ[\"prostatex_analysis\"] = os.path.join(os.getcwd(), \"prostatex_analysis\")\n","os.environ[\"prostatex_analysis_results\"] = os.path.join(os.environ[\"prostatex_analysis\"], \"results\")\n","os.environ[\"prostatex_analysis_verbose\"] = os.path.join(os.environ[\"prostatex_analysis\"], \"results_verbose\")\n","#radiomics"],"metadata":{"id":"Tm_wILGfRU7G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def reset_folders():\n","  for key, path in os.environ.items():\n","    check_patterns = [True for el in [\"nnunet_preds\", \"idc\",\n","                                      \"IDC\", \"prostatex_analysis\"] if el in key]\n","    if True in check_patterns:\n","      !rm -rf $path\n","      !mkdir -p $path"],"metadata":{"id":"EtaG_IfLJ3SA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We process each SerieUID one at a time, we first retrieve serieUIDs processed in GCP bucket and subtract that amount from the serieUIDs retrieved from custom processed BigQuery radiomics table, obtaining the non processed serieUID_current_lst.\n","\n","If that is not the desired behaviour :\n","\n","- select all seriesUID in the IDC MR T2 series bigquery cell -- uncomment UNNEST filter\n","- change not_processed_RefSerieUID below to list(selection_t2_df.SeriesInstanceUID.unique())"],"metadata":{"id":"mr-ecatn89f_"}},{"cell_type":"code","source":["#whole process\n","for serieUID_current in list(not_processed_RefSerieUID):#list(selection_t2_df.SeriesInstanceUID.unique())\n","  #reset processing folders\n","  reset_folders()\n","  #download nnunet data\n","  !gsutil -m cp -r gs://idc_qin_prostate_repeatability/model1/preds_processed_dcm/*{serieUID_current}* {os.environ['nnunet_preds_dcm']}/\n","  ##convert to nii\n","  convert_seg_to_nii(input_path=glob.glob(f\"{os.environ['nnunet_preds_dcm']}/*.dcm\")[0], \\\n","                    output_path=os.environ['nnunet_preds_nii'])\n","  #download_idc_data\n","  idc_data_df = selection_t2_df[selection_t2_df.SeriesInstanceUID \\\n","                                                           == serieUID_current]\n","  download_idc_data_serie_uid(idc_df=idc_data_df,\n","                              out_path=os.environ[\"idc_data_dcm\"],\n","                              out_path_nii=os.environ[\"idc_data_nii\"])\n","  assert len(np.unique(idc_data_df.SeriesInstanceUID.values)) == 1\n","  nnunet_dic = parse_json_dcmqi(glob.glob(os.path.join(os.environ[\"nnunet_preds_nii\"], \\\n","                                        \"**\", \"*.json\"), recursive=True)[0])\n","  print(f\"nnunet segment and labelIDs : {nnunet_dic}\")\n","  # compute_pyradiomics_3D_features()\n","  df_features = compute_pyradiomics_3D_features(glob.glob(os.environ[\"idc_data_nii\"]+\"/*.nii.gz\")[0],\n","                                              list(nnunet_dic.values()),\n","                                              list(nnunet_dic.keys()),\n","                                              os.environ[\"nnunet_preds_nii\"],\n","                                              nnunet_segments_code_mapping_df)\n","  features_extract = df_features[[\"VoxelVolume\", \"MeshVolume\", \"Sphericity\", \"ReferencedSegment\", \"label_name\"]]\n","  features_extract[\"MeshVolume\"] = features_extract.MeshVolume.apply(lambda x : x[()])\n","  features_extract[\"Sphericity\"] = features_extract.Sphericity.apply(lambda x : x[()])\n","  features_extract[\"RefSerieUID\"] = [serieUID_current for x in range(len(features_extract))]\n","  features_extract[\"collection_id\"] = [\"qin_prostate_repeatability\" for x in range(len(features_extract))]\n","  rows_to_insert = features_extract.to_dict('records')\n","  print(rows_to_insert)\n","  # upload to bigquery table\n","  # Construct a BigQuery client object.\n","  client = bigquery.Client()\n","  table_id = \"idc-sandbox-003.qin_prostate_repeatability_serieUID.model1_preds_prostate_radiomics\"\n","  errors = client.insert_rows_json(table_id, rows_to_insert)  # Make an API request.\n","  if errors == []:\n","      print(\"New rows have been added.\")\n","  else:\n","      print(\"Encountered errors while inserting rows: {}\".format(errors))"],"metadata":{"id":"_OzTkdEZEJZS"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1bCCNF1QHzA7JL3qP6oHsL67fL__5p9xo","timestamp":1684131563160},{"file_id":"1t9mnTxQfnqO7IGcyG0CeUla3aZygo8Mj","timestamp":1684131265263},{"file_id":"1_VtyrjdfRqe2waLI2cAsUj-g264yEzFv","timestamp":1683783630247},{"file_id":"14g1Vs5LlcbXGmCMG4tIN1rNVTVokYgYf","timestamp":1681923240531},{"file_id":"1zzbZ5cLeStImabaXSKR06azFpTIbnRox","timestamp":1681764723771},{"file_id":"14NRwvoWZlZNI2DbSI_T6hkowkJRDMOso","timestamp":1681406236695},{"file_id":"1UcDxYTvGhXFL1ZUDNkis3yJUln7PIA60","timestamp":1667231814832},{"file_id":"1LR11ePaeZdpsBDEH-hu59Rv85JoM-TAF","timestamp":1664223887456},{"file_id":"https://github.com/ccosmin97/IDC-Prostate_segmentation/blob/main/IDC_notebooks/idc-prostate_segmentation_prostate05_qin-rep-repeat.ipynb","timestamp":1661986443154}],"collapsed_sections":["zLvysANUArnm","40E3HnI5A0SX"],"machine_shape":"hm","toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}