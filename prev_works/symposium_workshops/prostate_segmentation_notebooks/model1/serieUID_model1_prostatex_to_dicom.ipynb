{"cells":[{"cell_type":"markdown","metadata":{"id":"WnbkuvxW0Ntp"},"source":["# Prostate segmentation on IDC collection -- MRI US Prostate Biopsy\n","*   Dataset : [ProstateX]()\n","*   Goal : Prostate segmentation using Task24 Prostate nnU-net pre-trained model, T2 input single-modality"]},{"cell_type":"markdown","metadata":{"id":"hYHTAtTsUgdB"},"source":["# Global variables"]},{"cell_type":"markdown","metadata":{"id":"yzDbwBXyvWVr"},"source":["## Variables used for resampling -- inference -- setup labelID for ground truth segs"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"bMsV_GPNvcip","executionInfo":{"status":"ok","timestamp":1687911197499,"user_tz":240,"elapsed":177,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"outputs":[],"source":["# IDC collection for paths setup\n","collection_name = \"prostatex\" #up to user\n","##nnunet\n","model_type = '3d_fullres'#other options are '2d',..\n","nnunet_labelID = 1 #unique values for nifti segmentation volumes predicted, here 1 is prostate and 0 is background\n","desired_grid = \"T2\" #Other option is \"ADC\""]},{"cell_type":"markdown","metadata":{"id":"uMtYZyHU7pIq"},"source":["## Global paths"]},{"cell_type":"markdown","source":["Here we create the necessary folders, IDC folders for download MR T2 data, and nnunet workspace."],"metadata":{"id":"JRlqCiSrOXiG"}},{"cell_type":"markdown","source":["nnUNet workspace :\n","\n","Three main variables are needed by default to run the nnU-Net segmentation pipelines:\n","* `nnUNet_raw_data_base` is the path to the folder where the segmentation pipeline expects to find the data to process;\n","* `nnUNet_preprocessed` is the path to the folder where the preprocessed data are saved;\n","* `RESULTS_FOLDER` is the path to the folder storing by default the model weights and, in our case, for simplicity, the segmentation masks produced by the pipeline.\n","\n","We will use the additional variable `PATH_TO_MODEL_FILE` to point to the location where the pre-trained model weights for the chosen model will be stored (more on this later).\n","\n","Please notice that these variables need to be set using `os.environ[]` in Google Colab - as `!export` is not sufficient to guarantee the variables are kept from one cell to the other. For more in-depth information regarding what the nnU-Net framework uses these folders for, please visit [the dedicated nnU-Net documentation page](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/setting_up_paths.md)"],"metadata":{"id":"yEi3Pm8YQCVq"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZC_bUbUTUgBs","executionInfo":{"status":"ok","timestamp":1687911199466,"user_tz":240,"elapsed":1786,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"outputs":[],"source":["import os\n","\n","#qin_prostate_repeatibility\n","os.environ[\"prostatex_root\"] = os.path.join(os.getcwd(), \"prostateX\")\n","os.environ[\"prostatex_dicom\"] = os.path.join(os.environ[\"prostatex_root\"], \"dicom\")\n","os.environ[\"prostatex_nii\"] = os.path.join(os.environ[\"prostatex_root\"], \"nii\")\n","\n","#nnunet\n","os.environ[\"nnUNet\"] = os.path.join(os.getcwd(), \"nnUNet\")\n","os.environ[\"nnUNet_data\"] = os.path.join(os.environ[\"nnUNet\"], \"data\")\n","os.environ['nnUNet_raw_data_base'] = os.path.join(os.environ[\"nnUNet_data\"], \"nnUNet_raw_data\")\n","os.environ['nnUNet_preprocessed'] = os.path.join(os.environ[\"nnUNet_data\"], \"processed\")\n","os.environ[\"nnUNet_models\"] = os.path.join(os.environ[\"nnUNet\"], \"models\")\n","os.environ[\"RESULTS_FOLDER\"] = os.path.join(os.environ[\"nnUNet\"], \"output\", \"preds\")\n","os.environ[\"nnUNet_preds_post_processed\"] = os.path.join(os.environ[\"nnUNet\"], \"output\", \"preds_processed\")\n","os.environ[\"nnUNet_preds_resampled\"] = os.path.join(os.environ[\"nnUNet\"], \"output\", \"preds_resampled\")\n","os.environ[\"nnUNet_preds_resampled_dcm\"] = os.path.join(os.environ[\"nnUNet\"], \"output\", \"preds_resampled_dcm\")\n","os.environ[\"nnUNet_raw_data\"] = os.path.join(os.environ[\"nnUNet\"], \"raw_data\")\n","#path where model pre-trained weights are stored\n","os.environ[\"PATH_TO_MODEL_FILE\"] = os.path.join(os.environ[\"nnUNet\"], \"models\", \"Task024_Prostate.zip\")\n","\n","#misc\n","os.environ[\"IDC_Downloads\"] = os.path.join(os.getcwd(), \"IDC_DL\")\n","os.environ[\"IDC_Downloads_Sorted\"] = os.path.join(os.getcwd(), \"IDC_DL\", \"Sorted\")\n","os.environ[\"logs\"] = os.path.join(os.getcwd(), \"logs\")\n","\n","#create dirs for specific folders names\n","for key, path in os.environ.items():\n","  check_patterns = [True for el in [\"prostatex\", \"nnunet\", \"IDC\", \"nnUNet\", \"logs\", \"RESULTS_FOLDER\"] if el in key]\n","  if True in check_patterns:\n","    !mkdir -p $path"]},{"cell_type":"markdown","source":["# Custom functions"],"metadata":{"id":"TZALQu_dnyFq"}},{"cell_type":"code","source":["def convert_image_dcm_to_nrrd(input_path, output_path_root, prefix=\"\"):\n","  \"\"\"\n","  Conversion of DICOM MR data to NIFTI using dcm2niix\n","  input_path : str, folder containing DICOM instances .dcm\n","  output_path_root : str, output folder\n","  prefix : str, prefix for output file name\n","  \"\"\"\n","  if not os.path.exists(output_path_root):\n","    !mkdir -p $output_path_root\n","  !dcm2niix -z y -m y -f %i_{prefix} -o $output_path_root $input_path"],"metadata":{"id":"ADnWwCO22Dpt","executionInfo":{"status":"ok","timestamp":1687911199466,"user_tz":240,"elapsed":8,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def convert_dcm_sorted(input_path,output_path, idc_df):\n","  \"\"\"\n","  Convert DCM MR sorted by PatID/StudyUID/SerieUID in NIFTI format\n","  input_path : str, root folder containing all series sorted by patid/studyUID/serieUID/sopUID.dcm\n","  output_path : str, root folder of where to store converted MR T2 series\n","  idc_df : pandas.Dataframe, contains IDC metadata to retrieve modality information etc per serieUID\n","  \"\"\"\n","  for serie_folder in sorted(glob.glob(os.path.join(input_path, \"**\", \"**\", \"*\"))):#grab serie folder in sorted MR IDC DICOM data folder\n","    path_serie_dcm_lst = glob.glob(os.path.join(serie_folder, \"*.dcm\"))\n","    modality = idc_df[idc_df[\"SeriesInstanceUID\"] == path_serie_dcm_lst[0].split('/')[-2]][\"Modality\"].iloc[0]#get modality per serie\n","    seriesInstanceUID = serie_folder.split(\"/\")[-1]\n","    studyInstanceUID = serie_folder.split(\"/\")[-2]\n","    patientID = serie_folder.split(\"/\")[-3]\n","    print(f\"Serie processed : {serie_folder}\")\n","    print(f\"SeriesDescription : {pydicom.read_file(glob.glob(os.path.join(serie_folder, '*.dcm'))[0]).SeriesDescription}\")\n","    print(f\"Modality : {pydicom.read_file(glob.glob(os.path.join(serie_folder, '*.dcm'))[0]).Modality}\")\n","    #convert to NIFTI\n","    convert_image_dcm_to_nrrd(input_path=serie_folder,\n","                           output_path_root=os.path.join(output_path, \"nii\"),\n","                           prefix=f\"{seriesInstanceUID}\")"],"metadata":{"id":"HO2dWXPBF3Sf","executionInfo":{"status":"ok","timestamp":1687911199467,"user_tz":240,"elapsed":8,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def download_idc_data_serie_uid(idc_df):\n","  \"\"\"\n","  Download IDC data from gcs_urls retrieved from BigQuery\n","  idc_df : pandas.Dataframe, contains MR series DICOM metadata and gcs_urls\n","  \"\"\"\n","  # save the list of GCS URLs into a file\n","  selection_manifest = os.path.join(os.environ[\"IDC_Downloads\"], \"idc_manifest.txt\")\n","  idc_df[\"gcs_url\"].to_csv(selection_manifest, header=False, index=False)\n","  !cat {selection_manifest} | gsutil -m cp -I {os.environ[\"IDC_Downloads\"]}#download gcs_urls into output_folder\n","  #sort dicom donwload data per PatID/studyUID/serieUID\n","  !python dicomsort/dicomsort.py -k -u {os.environ[\"IDC_Downloads\"]} {os.environ[\"IDC_Downloads_Sorted\"]}/%PatientID/%StudyInstanceUID/%SeriesInstanceUID/%SOPInstanceUID.dcm\n","  !mv {os.environ['IDC_Downloads_Sorted']+'/*'} {os.environ[\"prostatex_dicom\"]}#move sorted IDC DICOM data to prostatex_dicom folder\n","  #Convert to NIFTI\n","  convert_dcm_sorted(input_path=os.environ[\"prostatex_dicom\"],\n","                  output_path=os.environ[\"prostatex_root\"], idc_df=selection_df)\n","  return selection_df"],"metadata":{"id":"Fj5E_8qrGcjP","executionInfo":{"status":"ok","timestamp":1687911199467,"user_tz":240,"elapsed":7,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def reformat_image_nnunet():\n","  \"\"\"\n","  formats input MR T2 data into nnunet ready format, caseID_Modality.nii.gz, where modality here is T2==0000\n","  \"\"\"\n","  #reformats images to correct format,\n","  for mr_vol in glob.glob(os.path.join(os.environ[\"prostatex_nii\"], f\"*.nii.gz\")):#get MR T2 NIFTI volume\n","    serieUID = mr_vol.split('/')[-1].split(\"_\")[1].replace(\".nii.gz\",\"\")#.split(\".\")[0]\n","    patientID = mr_vol.split('/')[-1].split(\"_\")[0]\n","    nnunet_idx = \"0000\" #if \"T2\" in mr_vol.split('/')[-2] else \"0001\"#0000 for T2 and 0001 for ADC\n","    nnunet_path = os.path.join(os.environ[\"nnUNet_preprocessed\"],\n","                                \"_\".join([patientID, serieUID, nnunet_idx]) + \".nii.gz\")\n","    !cp $mr_vol $nnunet_path"],"metadata":{"id":"nfxSP-K6GpFD","executionInfo":{"status":"ok","timestamp":1687911199468,"user_tz":240,"elapsed":8,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def largest_component_retrieval(input_path : str, output_path=None):\n","    \"\"\"\n","    Largest component retrieval\n","    input_path : str, input seg nifti path, binary image\n","    output_path :str, output_path after conversion\n","    Convert binary image into a connected component image, each component has an integer label.\n","    Relabel components so that they are sorted according to size (there is an optional minimumObjectSize parameter to get rid of small components).\n","    Get largest connected componet, label==1 in sorted component image.\n","    \"\"\"\n","    assert os.path.exists(input_path)\n","    input_image = sitk.ReadImage(input_path, imageIO=\"NiftiImageIO\")\n","    assert len(np.unique(sitk.GetArrayFromImage(input_image))) == 2 # make sure its a binary image\n","    component_image = sitk.ConnectedComponent(input_image)\n","    sorted_component_image = sitk.RelabelComponent(component_image, sortByObjectSize=True)\n","    largest_component_binary_image = sorted_component_image == 1\n","    if output_path is not None:\n","        # assert os.path.exists(output_path)\n","        print(output_path)\n","        sitk.WriteImage(largest_component_binary_image, output_path, imageIO=\"NiftiImageIO\")\n","    else:\n","        print(\"No writing on disk of largest component of input.\")\n","    # sanity checks == logs\n","    print(f\"Input path : {input_path}\")\n","    print(f\"Output path : {output_path}\")\n","    print(f\"Number of components found : {len(np.unique(sitk.GetArrayFromImage(sorted_component_image)))}\")\n","    # print(\"Done!\")\n","    # print(\"\\n\")"],"metadata":{"id":"Z_Xrcq4nHOa9","executionInfo":{"status":"ok","timestamp":1687911199469,"user_tz":240,"elapsed":8,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def resample_preds(input_path_nnunet_preds=\"\", input_path_t2_idc=\"\", output_path=\"\"):\n","  \"\"\"\n","  Resampling of nnunet_preds to reference MR T2 volumes used as input image\n","  input_path_nnunet_preds : str, folder containing nnunet preds\n","  input_path_t2_idc : str, folder containing NIFTI IDC MR T2 volumes\n","  output_path : str, folder output\n","  \"\"\"\n","  for pred_path in sorted(glob.glob(os.path.join(input_path_nnunet_preds, \"*.nii.gz\"))):\n","    search_t2_path = os.path.join(input_path_t2_idc, \\\n","                                  f\"{pred_path.split('/')[-1].split('_')[0]}_{pred_path.split('/')[-1].split('_')[1].replace('.nii.gz','')}*.nii.gz\") #PatientID_SerieUID.nii.gz\n","                                      #get serieUID\n","    print(f\"search path for {desired_grid} : {search_t2_path}\")\n","    t2_path = glob.glob(search_t2_path, recursive=True)[0]\n","    print(f\"{desired_grid}_path found : {t2_path}\")\n","    print(f\"pred path : {pred_path}\")\n","    out_processed = os.path.join(os.environ[\"nnUNet_preds_post_processed\"], pred_path.split(\"/\")[-1])\n","    largest_component_retrieval(input_path=pred_path,output_path=out_processed)\n","    resample_args_to_t2_origin = {\"input\" : out_processed,#change to pred path if no largest_component_retrieval necessary\n","                          \"output\" : os.path.join(output_path,\n","                                                  f\"{pred_path.split('/')[-1][:-7]}_resampled.nii.gz\"),\n","                          \"fixed\" : t2_path,\n","                          \"interpolation\" : \"nn\"}\n","\n","    path_log = os.path.join(os.environ[\"logs\"], 'log_pypla_res_pred' + pred_path.split('/')[-1].split('.')[0] + '.txt')\n","    !touch $path_log\n","    pypla.resample(verbose = False, **resample_args_to_t2_origin, path_to_log_file=path_log)\n","    print()"],"metadata":{"id":"LE6hjzqkIiAy","executionInfo":{"status":"ok","timestamp":1687911199470,"user_tz":240,"elapsed":9,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def seg_nii_to_dicom(idc_df, input_path_nii=\"\", input_path_dcm_idc=\"\", output_path_root=\"\"):\n","  \"\"\"\n","  Convert of NIFTI binary segmentations of nnunet to SEG DICOM object\n","  idc_df : pandas.Dataframe, resulting from Bigquery\n","  input_path_nii : str, nnunet_preds folder\n","  input_path_dcm_idc : str,  folder containing DCM IDC MR T2 objects\n","  output_path_root : str, output_path root folder\n","  \"\"\"\n","  assert os.path.exists(input_path_nii)\n","  assert os.path.exists(input_path_dcm_idc)\n","  !mkdir -p $output_path_root\n","  for nii_seg_pred in glob.glob(os.path.join(input_path_nii, '*.nii.gz')):\n","    patID = nii_seg_pred.split('/')[-1].split('_')[0]\n","    study_mr_t2_serieUID = nii_seg_pred.split('/')[-1].split('_')[1].replace(\".nii.gz\",\"\")\n","    #find t2 dcm folder\n","    t2_dcm_folder = glob.glob(os.path.join(input_path_dcm_idc, patID, \"**\", study_mr_t2_serieUID))[0]\n","    #find seg dcm file\n","    # find nii seg folder == preds resampled\n","    assert os.path.exists(t2_dcm_folder)\n","    print('\\nConverting...')\n","    print(f'pred nnunet processed : {nii_seg_pred}')\n","    print(f't2_dcm_folder : {t2_dcm_folder}')\n","    output_path = os.path.join(output_path_root, '_'.join([patID, study_mr_t2_serieUID])+'.dcm')\n","    #convert nii pred to dcm\n","    !itkimage2segimage --inputImageList $nii_seg_pred \\\n","    --inputDICOMDirectory  $t2_dcm_folder \\\n","    --inputMetadata  $seg_dcm_metadata_json_file \\\n","    --outputDICOM $output_path\n","    print(\"Done!\")"],"metadata":{"id":"7RS5TpGSGoe6","executionInfo":{"status":"ok","timestamp":1687911199471,"user_tz":240,"elapsed":9,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Db4ansTyzqZ1"},"source":["# Auth login"]},{"cell_type":"markdown","metadata":{"id":"a8GPDXZW00j5"},"source":["##Colab"]},{"cell_type":"markdown","source":["Google Colab authentification, necessary step to link account to GCP project to retrieve IDC data through BigQuery"],"metadata":{"id":"T-X-xwtmPr-m"}},{"cell_type":"code","execution_count":10,"metadata":{"id":"XSg6W2HXzsoG","executionInfo":{"status":"ok","timestamp":1687911207596,"user_tz":240,"elapsed":8134,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"outputs":[],"source":["#colab\n","from google.colab import auth\n","auth.authenticate_user()"]},{"cell_type":"markdown","metadata":{"id":"y1ZYYVPHz_xm"},"source":["# Setup GCP Project ID"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"g1EN9Dnz0CU4","executionInfo":{"status":"ok","timestamp":1687911207596,"user_tz":240,"elapsed":6,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"outputs":[],"source":["project_id = \"idc-sandbox-003\"\n","os.environ[\"GCP_PROJECT_ID\"] = project_id"]},{"cell_type":"markdown","metadata":{"id":"eRtmCas7dT6D"},"source":["# Setup of the Colab VM\n","\n","\n","\n","In the following cells we will confirm you have a GPU before doing anything else, and will install and import all the Python dependencies.\n","\n","The main python packages we need to install are:\n","* `nnunet` - which is the [codebase for the nn-UNet framework](https://github.com/MIC-DKFZ/nnUNet) we are going to be using for the segmentation step;\n","* `pydicom`, a Python [package](https://github.com/pydicom/pydicom) that lets the use read, modify, and write DICOM data in an easy \"pythonic\" way - that we are going to use to distinguish different DICOM objects from each other."]},{"cell_type":"markdown","metadata":{"id":"zLvysANUArnm"},"source":["## GPU checks"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Pf2j172mddvK","executionInfo":{"status":"ok","timestamp":1687911207768,"user_tz":240,"elapsed":177,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"outputs":[],"source":["# check wether the Colab Instance was correctly initialized with a GPU instance\n","gpu_list = !nvidia-smi --list-gpus\n","\n","has_gpu = False if \"failed\" in gpu_list[0] else True\n","\n","if not has_gpu:\n","  print(\"Your Colab VM does not have a GPU - check \\\"Runtime > Change runtime type\\\"\")"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"kL6xCvo3eKQ0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687911207926,"user_tz":240,"elapsed":162,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"4b0af64c-876c-453a-a3a6-32979d448f73"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Jun 28 00:13:28 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# check which model of GPU the notebook is equipped with - a Tesla K80 or T4\n","# T4 is the best performing on the two - and can about half the GPU processing time\n","\n","!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"40E3HnI5A0SX"},"source":["## Install command-line tools\n","\n","\n","[Plastimatch](https://plastimatch.org/index.html) is considered to be the swiss army knife of medical images processing: we will use it to convert DICOM (CT, RTSTRUCT) series to NRRD files - but it can be used for a multitude of other tasks, such as registration, resampling, cropping, and computing statistics to name a few. Plastimatch is also available as a 3DSlicer plug-in and can be used directly from the Slicer GUI.\n","\n","For the sake of clarity and simplicity, we will call Plastimatch from a very simple [Python wrapper](https://github.com/denbonte/pyplastimatch) written for the occasion (unfortunately, Plastimatch does not provide an official one)."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"ZZL6-ByHA7XY","executionInfo":{"status":"ok","timestamp":1687911231749,"user_tz":240,"elapsed":23825,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"outputs":[],"source":["%%capture\n","!sudo apt update\n","\n","!sudo apt install plastimatch"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"LMovHnKgBEfC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687911231913,"user_tz":240,"elapsed":167,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"5502c556-9bd6-4172-d698-2b695f0ac337"},"outputs":[{"output_type":"stream","name":"stdout","text":["plastimatch version 1.8.0\n"]}],"source":["!echo $(plastimatch --version)"]},{"cell_type":"markdown","metadata":{"id":"K_8zlhmdo0HD"},"source":["[dcmqi](https://github.com/QIICR/dcmqi) is an open source library that can help with the conversion between imaging research formats and the standard DICOM representation for image analysis results. More specifically, you can use dcmqi convert DICOM Segmentation objects (DICOM SEG) into research formats, such as NIfTI and NRRD."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"KAkmz4jApGh8","executionInfo":{"status":"ok","timestamp":1687911233074,"user_tz":240,"elapsed":1163,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"outputs":[],"source":["%%capture\n","!wget https://github.com/QIICR/dcmqi/releases/download/v1.2.5/dcmqi-1.2.5-linux.tar.gz\n","!tar zxvf dcmqi-1.2.5-linux.tar.gz\n","!cp dcmqi-1.2.5-linux/bin/* /usr/local/bin/"]},{"cell_type":"markdown","metadata":{"id":"fFRWendbBH72"},"source":["Finally, we are going to install [Subversion](https://subversion.apache.org/), a tool that will allow us to clone GitHub repositories only partially (to save time and space)."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"YBEJRe-2BKah","executionInfo":{"status":"ok","timestamp":1687911238015,"user_tz":240,"elapsed":4943,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"outputs":[],"source":["%%capture\n","\n","!sudo apt install subversion"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"WI1_BixWBN1O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687911238195,"user_tz":240,"elapsed":191,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"f8505b7d-e692-4ec2-c39a-a199fc883b05"},"outputs":[{"output_type":"stream","name":"stdout","text":["svn, version 1.13.0 (r1867053) compiled May 12 2022, 20:47:08 on x86_64-pc-linux-gnu\n"]}],"source":["!echo $(svn --version | head -n 2)"]},{"cell_type":"markdown","metadata":{"id":"0Ev-JlpCAuMs"},"source":["## Install Python packages"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"7XMzq-8nRvKd","executionInfo":{"status":"ok","timestamp":1687911300617,"user_tz":240,"elapsed":62423,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"outputs":[],"source":["%%capture\n","!pip install nnunet\n","!pip install pydicom\n","!pip install nibabel\n","!pip install dcm2niix\n","!pip install SimpleITK"]},{"cell_type":"markdown","metadata":{"id":"62yhEkkjITzn"},"source":["Unpack and install model we downloaded earlier (under `PATH_TO_MODEL_FILE`). This step can take about 1-2 minutes."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"QOVsPuzxIOXX","executionInfo":{"status":"ok","timestamp":1687911300780,"user_tz":240,"elapsed":168,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"outputs":[],"source":["%%capture\n","!nnUNet_install_pretrained_model_from_zip $PATH_TO_MODEL_FILE"]},{"cell_type":"markdown","metadata":{"id":"BP1tahM9tzlm"},"source":["Next we set up few things to help with visualization of the segmentations later."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"cURjj8rzAa2L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687911301452,"user_tz":240,"elapsed":674,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"1c081dfd-afb4-47b9-a09c-55421b7d3845"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","This Colab instance is equipped with a GPU.\n"]}],"source":["import os\n","import sys\n","import shutil\n","import csv\n","import random\n","\n","import os\n","import glob\n","import csv\n","import json\n","\n","import nibabel as nib\n","\n","import time\n","import gdown\n","\n","import json\n","import pprint\n","import numpy as np\n","import pandas as pd\n","\n","import pydicom\n","import nibabel as nib\n","import SimpleITK as sitk\n","\n","# from medpy.metric.binary import dc as dice_coef\n","# from medpy.metric.binary import hd as hausdorff_distance\n","# from medpy.metric.binary import asd as avg_surf_distance\n","\n","# from medpy.filter.binary import largest_connected_component\n","\n","# use the \"tensorflow_version\" magic to make sure TF 1.x is imported\n","# %tensorflow_version 2.x\n","# import tensorflow as tf\n","# import keras\n","\n","print(\"\\nThis Colab instance is equipped with a GPU.\")"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"UrAh2kjqb2Be","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687911302233,"user_tz":240,"elapsed":783,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"4df3c795-9a78-41b9-f770-9ef8acc83988"},"outputs":[{"output_type":"stream","name":"stdout","text":["A    pyplastimatch/__init__.py\n","A    pyplastimatch/pyplastimatch.py\n","A    pyplastimatch/utils\n","A    pyplastimatch/utils/__init__.py\n","A    pyplastimatch/utils/data.py\n","A    pyplastimatch/utils/eval.py\n","A    pyplastimatch/utils/viz.py\n","Checked out revision 25.\n"]}],"source":["# PyPlastimatch - python wrapper for Plastimatch (and interactive notebook visualisation)\n","!svn checkout https://github.com/AIM-Harvard/pyplastimatch/trunk/pyplastimatch pyplastimatch"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"GsePTNBmM9sw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687911303094,"user_tz":240,"elapsed":862,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"5e573163-ad0e-43e1-b6dd-9f3a718321a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'dicomsort'...\n","remote: Enumerating objects: 169, done.\u001b[K\n","remote: Counting objects: 100% (43/43), done.\u001b[K\n","remote: Compressing objects: 100% (26/26), done.\u001b[K\n","remote: Total 169 (delta 23), reused 34 (delta 17), pack-reused 126\u001b[K\n","Receiving objects: 100% (169/169), 87.85 KiB | 6.27 MiB/s, done.\n","Resolving deltas: 100% (86/86), done.\n"]}],"source":["# dicomsort is the pythong package that can sort DICOM files into\n","# folder organization based on user-specified DICOM attributes\n","!git clone https://github.com/pieper/dicomsort.git"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"0s9aRassGOQ_","executionInfo":{"status":"ok","timestamp":1687911303095,"user_tz":240,"elapsed":4,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"outputs":[],"source":["from pyplastimatch import pyplastimatch as pypla\n","from pyplastimatch.utils import viz as viz_utils\n","from pyplastimatch.utils import data as data_utils"]},{"cell_type":"markdown","metadata":{"id":"Duil1tviGWaG"},"source":["# Data selection, downloading and structuring -- Conversion to DICOM\n","\n","We want to select here the collection named qin-prostate repeatibility, and more particularly the two timepoints per patient ID for further analysis."]},{"cell_type":"markdown","metadata":{"id":"naJ5OAKZnZpG"},"source":["In order to use data hosted by IDC effectively, you will need to utilize metadata to navigate what data is available and to select specific files that are relevant in your analysis. The main metadata table you will need for this purpose is the [`bigquery-public-data.idc_current.dicom_all`](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=idc_current&t=dicom_all&page=table) table.\n","\n","This query has one row per file hosted by IDC. All of IDC data is in DICOM format, and each of the rows in this table will have all of the DICOM attributes extracted from a given file. It will also have various columns containing non-DICOM metadata, such as the name of the collection where the file is included, size of the file, and URL that can be used to retrieve that file.\n","\n","To query IDC BigQuery tables, you can use one of the following approaches:\n","1. `%%bigquery` magic will allow you to define your query in plain SQL, and load the result of the query into a Pandas dataframe.\n","2. [BigQuery Python API](https://googleapis.dev/python/bigquery/latest/index.html) is more flexible in allowing you to parameterize your query.\n","3. [Google Cloud BigQuery console](https://console.cloud.google.com/bigquery) is very convenient for interactive query exploration of tables.\n","4. [`gcloud bq`](https://cloud.google.com/bigquery/docs/bq-command-line-tool) is the command line tool that comes as part of [Cloud SDK](https://cloud.google.com/sdk) and is convenient for scripting interactions from the shell. Cloud SDK is preinstalled on Colab.\n","\n","In the following cells we will utilize `%%bigquery`, Python BigQuery SDK and BigQuery console for working with IDC BigQuery tables.\n","\n","First, to verify that you are authenticated, and your project ID is working, let's run a test query against IDC BigQuery table to get the summary statistics about the  of data available in IDC.\n"]},{"cell_type":"markdown","metadata":{"id":"t9YKMGVvVZX_"},"source":["Given `SeriesInstanceUID` value identifying the image series, we can query the IDC metadata table to get the list of files (defined by the Google Storage URLs) corresponding to this series.\n","\n","All of the DICOM metadata for each of the DICOM files is available in the BigQuery table we will be querying. We will get not just the `gcs_url`, but also identifiers for the Study, Series and Instance, to better understand organization of data, and since `StudyInstanceUID` will be handy later when we get to the visualization of the data."]},{"cell_type":"code","source":["from google.cloud import bigquery\n","bq_client = bigquery.Client(os.environ[\"GCP_PROJECT_ID\"])"],"metadata":{"id":"uYRrCmMAaUaQ","executionInfo":{"status":"ok","timestamp":1687911303096,"user_tz":240,"elapsed":4,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["selection_query = f\"\"\"\n","  -- get all prostatex segmentations objects\n","WITH\n","  prostatex_seg AS (\n","  SELECT\n","    DISTINCT(ReferencedSeriesSequence[SAFE_OFFSET(0)].SeriesInstanceUID) AS RefSerieUID\n","  FROM\n","    `bigquery-public-data.idc_v14.dicom_all`\n","  WHERE\n","    collection_id = 'prostatex'\n","    AND SegmentSequence[SAFE_OFFSET(0)].SegmentedPropertyTypeCodeSequence[SAFE_OFFSET(0)].CodeMeaning = 'Prostate'\n","    AND SegmentSequence[SAFE_OFFSET(0)].SegmentedPropertyTypeCodeSequence[SAFE_OFFSET(0)].CodeValue = '41216001' )\n","SELECT\n","  dc_all.*\n","FROM\n","  `bigquery-public-data.idc_v14.dicom_all` AS dc_all\n","JOIN\n","  prostatex_seg\n","ON\n","  dc_all.SeriesInstanceUID = prostatex_seg.RefSerieUID\n","WHERE\n","  dc_all.collection_id = 'prostatex'\n","  AND dc_all.Modality = 'MR'\n","  AND LOWER(dc_all.SeriesDescription) LIKE '%t2%'\n","ORDER BY\n","  PatientID\"\"\"\n","selection_result = bq_client.query(selection_query)\n","selection_df = selection_result.result().to_dataframe()"],"metadata":{"id":"RgyrGJmvaTM1","executionInfo":{"status":"ok","timestamp":1687911314236,"user_tz":240,"elapsed":11144,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["Get SerieUIDs in GCP bucket processed by nnunet AI model"],"metadata":{"id":"QjirvyGv_poC"}},{"cell_type":"code","source":["!rm bucketUIDs_processed.csv\n","!gcloud storage ls --recursive gs://idc_prostatex/model1/preds_processed_dcm/* > bucketUIDs_processed.csv\n","sereUID_processed_dcm = pd.read_csv(\"bucketUIDs_processed.csv\", names=[\"serieUID\"], skiprows=[0])\n","seriesInstanceUID_dcm_processed_lst = [x.split(\"/\")[-1].split(\"_\")[1].replace(\".dcm\", \"\") for x in sereUID_processed_dcm.serieUID.values]"],"metadata":{"id":"W_dEHcFc0mV9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687911316965,"user_tz":240,"elapsed":2740,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"1fd9a0fd-02f3-4c8b-c00a-e858a7ffb586"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["rm: cannot remove 'bucketUIDs_processed.csv': No such file or directory\n"]}]},{"cell_type":"code","source":["serieUID_current_lst = list(set(selection_df.SeriesInstanceUID.values) - set(seriesInstanceUID_dcm_processed_lst))"],"metadata":{"id":"nKpL6IbQ077V","executionInfo":{"status":"ok","timestamp":1687911316966,"user_tz":240,"elapsed":16,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["len(serieUID_current_lst)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rM9DaXYw1FBU","executionInfo":{"status":"ok","timestamp":1687911316967,"user_tz":240,"elapsed":16,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"c81b4bfa-6ad3-4513-8395-ec90728762f7"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["# Main loop"],"metadata":{"id":"kNuuz_84JqnK"}},{"cell_type":"markdown","source":["Download json metadata template for conversion of nnunet preds into DICOM"],"metadata":{"id":"__bJuQFJVfwq"}},{"cell_type":"code","source":["seg_whole_prostate_json = \"https://www.dropbox.com/s/yhkqnbqqc9fhgps/task024_whole_prostate.json?dl=0\"\n","seg_dcm_metadata_json_file = \"pred_metadata.json\"#\"/content/nnUnet/models/Task024_Promise.zip\"\n","!wget -O $seg_dcm_metadata_json_file $seg_whole_prostate_json"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-2P4a0HPelLq","executionInfo":{"status":"ok","timestamp":1687911317934,"user_tz":240,"elapsed":979,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}},"outputId":"01590839-3294-4c50-f127-84e16e995836"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-06-28 00:15:17--  https://www.dropbox.com/s/yhkqnbqqc9fhgps/task024_whole_prostate.json?dl=0\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: /s/raw/yhkqnbqqc9fhgps/task024_whole_prostate.json [following]\n","--2023-06-28 00:15:17--  https://www.dropbox.com/s/raw/yhkqnbqqc9fhgps/task024_whole_prostate.json\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc0184a5bd078e77d9326e380854.dl.dropboxusercontent.com/cd/0/inline/B-3hIyMWB0KsHhTpbd-WI6FGSD0Luja1xvprcf9JuF6ISYrP3ceqL35cklCK6Ft7nyyBdvuV-BNf_ty_CR9frcNZzu93UawjoDj0NrraCg2bZnBnI8FNUqovM5pVJxKiON-4gtyzRANWdMwKf9Vhs_XgqmvxdMX9ogreriMtxVSE1g/file# [following]\n","--2023-06-28 00:15:18--  https://uc0184a5bd078e77d9326e380854.dl.dropboxusercontent.com/cd/0/inline/B-3hIyMWB0KsHhTpbd-WI6FGSD0Luja1xvprcf9JuF6ISYrP3ceqL35cklCK6Ft7nyyBdvuV-BNf_ty_CR9frcNZzu93UawjoDj0NrraCg2bZnBnI8FNUqovM5pVJxKiON-4gtyzRANWdMwKf9Vhs_XgqmvxdMX9ogreriMtxVSE1g/file\n","Resolving uc0184a5bd078e77d9326e380854.dl.dropboxusercontent.com (uc0184a5bd078e77d9326e380854.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n","Connecting to uc0184a5bd078e77d9326e380854.dl.dropboxusercontent.com (uc0184a5bd078e77d9326e380854.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 983 [text/plain]\n","Saving to: ‘pred_metadata.json’\n","\n","pred_metadata.json  100%[===================>]     983  --.-KB/s    in 0s      \n","\n","2023-06-28 00:15:18 (285 MB/s) - ‘pred_metadata.json’ saved [983/983]\n","\n"]}]},{"cell_type":"markdown","source":["## Download and install nnUnet pre-trained model -- task024 -- personal dropbox\n","\n","nnUnet pre-trained models zip files can also be found [here](https://zenodo.org/record/4003545#.YsWmH-zMLt8)."],"metadata":{"id":"7v-ueJwA_STo"}},{"cell_type":"code","source":["%%capture\n","# this will usually take between one and five minutes (but can sometimes take up to eight)\n","seg_model_url = \"https://www.dropbox.com/s/u9m37l8et4hgu4h/Task024_Promise.zip?dl=0\"\n","out_path_mod = os.path.join(os.environ[\"nnUNet_models\"], \"Task024_Promise.zip\")#\"/content/nnUnet/models/Task024_Promise.zip\"\n","!wget -O $out_path_mod $seg_model_url\n","!nnUNet_install_pretrained_model_from_zip $out_path_mod"],"metadata":{"id":"oduKYG0G-68Y","executionInfo":{"status":"ok","timestamp":1687911359396,"user_tz":240,"elapsed":41466,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def reset_folders():\n","  for key, path in os.environ.items():\n","    check_patterns = [True for el in [\"nnUNet_preprocessed\", \"nnUNet_preds_post_processed\", \\\n","                                      \"prostatex\", \"IDC_Downloads\", \"IDC_Downloads_Sorted\", \\\n","                                      \"prostatex_dicom\", \"prostatex_root\", \"nnUNet_preds_resampled\"] if el in key]\n","    if True in check_patterns:\n","      !rm -rf $path\n","      !mkdir -p $path\n","  !rm /content/nnUNet/output/preds/*.nii.gz"],"metadata":{"id":"EtaG_IfLJ3SA","executionInfo":{"status":"ok","timestamp":1687911359397,"user_tz":240,"elapsed":6,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["We process each SerieUID one at a time, we first retrieve serieUIDs processed in GCP bucket and subtract that amount from the serieUIDs retrieved from IDC MR T2 series, obtaining the non processed serieUID_current_lst.\n","\n","If that is not the desired behaviour, change serieUID_current_lst below to list((selection_df.SeriesInstanceUID.unique())"],"metadata":{"id":"0faeR0n0uEMB"}},{"cell_type":"code","source":["#whole process\n","for serieUID_current in serieUID_current_lst:#list((selection_df.SeriesInstanceUID.unique())\n","  #reset processing folders\n","  reset_folders()\n","  #download idc data\n","  idc_df = download_idc_data_serie_uid(idc_df=selection_df[selection_df.SeriesInstanceUID \\\n","                                                           == serieUID_current])\n","  ##reformat idc input data\n","  reformat_image_nnunet()\n","  # Inference on IDC data\n","  !nnUNet_predict --input_folder {os.environ[\"nnUNet_preprocessed\"]} \\\n","                --output_folder {os.environ[\"RESULTS_FOLDER\"]} \\\n","                --task_name \"Task024_Promise\" --model $model_type \\\n","                --save_npz\n","  # resample\n","  resample_preds(input_path_nnunet_preds=os.environ[\"RESULTS_FOLDER\"],\\\n","                  input_path_t2_idc=os.environ[\"prostatex_nii\"], output_path=os.environ[\"nnUNet_preds_resampled\"])\n","  # Convert nnunet preds to dicom\n","  seg_nii_to_dicom(idc_df=idc_df, input_path_nii=os.environ[\"nnUNet_preds_resampled\"], \\\n","                   input_path_dcm_idc=os.environ[\"prostatex_dicom\"], output_path_root=os.environ[\"nnUNet_preds_resampled_dcm\"])\n","  #upload to buckets\n","  # !gsutil -m cp -r {os.environ['nnUNet_preds_resampled_dcm']}/* gs://idc_prostatex/model1/preds_processed_dcm/"],"metadata":{"id":"_OzTkdEZEJZS","executionInfo":{"status":"ok","timestamp":1687911359397,"user_tz":240,"elapsed":5,"user":{"displayName":"Cosmin Ciausu","userId":"01060908221005396239"}}},"execution_count":33,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1whP7rHFTm2byqTtf4d8CbgToENthVQg5","timestamp":1683335431721},{"file_id":"14g1Vs5LlcbXGmCMG4tIN1rNVTVokYgYf","timestamp":1681923240531},{"file_id":"1zzbZ5cLeStImabaXSKR06azFpTIbnRox","timestamp":1681764723771},{"file_id":"14NRwvoWZlZNI2DbSI_T6hkowkJRDMOso","timestamp":1681406236695},{"file_id":"1UcDxYTvGhXFL1ZUDNkis3yJUln7PIA60","timestamp":1667231814832},{"file_id":"1LR11ePaeZdpsBDEH-hu59Rv85JoM-TAF","timestamp":1664223887456},{"file_id":"https://github.com/ccosmin97/IDC-Prostate_segmentation/blob/main/IDC_notebooks/idc-prostate_segmentation_prostate05_qin-rep-repeat.ipynb","timestamp":1661986443154}],"machine_shape":"hm","toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}